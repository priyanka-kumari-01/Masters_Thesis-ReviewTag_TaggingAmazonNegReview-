{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["TvCDLKQpKYeg","7LWp0OaGKVSF","x6yCYZsTKK1O","nhkHzJ9vKHFp"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"2e2b40c5004045d487f581ada1307c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ced28e7ea16e4c508bf6870bae93ef96","IPY_MODEL_fb84e9c3af4340b39edc58fb0c031f7e","IPY_MODEL_f4b5579f52894abfbf498cdd3cc21f56"],"layout":"IPY_MODEL_37462b8a7dcb4e13b9f51903405f014e"}},"ced28e7ea16e4c508bf6870bae93ef96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37be122c4c874906ab3ceed8ec68abcb","placeholder":"​","style":"IPY_MODEL_a06cd0ee43a74686872c1d4ef3a5ebd2","value":"Downloading pytorch_model.bin: 100%"}},"fb84e9c3af4340b39edc58fb0c031f7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f705ec386bdd4bbc9453ee160fc4bf51","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01c8a1b8326043d5afa98d18d61838d7","value":501200538}},"f4b5579f52894abfbf498cdd3cc21f56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_749a45199b4d47f5b6f93fcfb31d84c8","placeholder":"​","style":"IPY_MODEL_d666ca3e217440a89694739e7da7c8ff","value":" 501M/501M [00:01&lt;00:00, 345MB/s]"}},"37462b8a7dcb4e13b9f51903405f014e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37be122c4c874906ab3ceed8ec68abcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a06cd0ee43a74686872c1d4ef3a5ebd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f705ec386bdd4bbc9453ee160fc4bf51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01c8a1b8326043d5afa98d18d61838d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"749a45199b4d47f5b6f93fcfb31d84c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d666ca3e217440a89694739e7da7c8ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Amazon Review- Tagging Negative Review in Amazon Product Review with BERT Model"],"metadata":{"id":"RNJz9jwRKq_c"}},{"cell_type":"markdown","source":["#Introduction"],"metadata":{"id":"P6c05iVMKq1v"}},{"cell_type":"markdown","source":["### Connecting to Golab Colab"],"metadata":{"id":"Vb5wmXi2KpEf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Jrd1u-H0J6eL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681957855981,"user_tz":300,"elapsed":18801,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}},"outputId":"1d082427-98c6-46e6-e6ea-1f18c0237f04"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q transformers"],"metadata":{"id":"HSjfWBFvl0xp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681957872160,"user_tz":300,"elapsed":12466,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}},"outputId":"1b98dc9a-0739-4dc3-9243-00e1206a73db"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["### Importing Libraries"],"metadata":{"id":"TvCDLKQpKYeg"}},{"cell_type":"code","source":["import csv\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","import time\n","import torch\n","from tabulate import tabulate\n","from torch import cuda\n","from torch.utils.data import Dataset, DataLoader\n","import transformers\n","from transformers import AutoTokenizer, AutoModel"],"metadata":{"id":"KNgM5DrshncN","executionInfo":{"status":"ok","timestamp":1681957878393,"user_tz":300,"elapsed":6238,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Check Device"],"metadata":{"id":"7LWp0OaGKVSF"}},{"cell_type":"code","source":["device = 'cuda' if cuda.is_available() else 'cpu'"],"metadata":{"id":"qx3_9p8smenl","executionInfo":{"status":"ok","timestamp":1681957878394,"user_tz":300,"elapsed":7,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Dataset"],"metadata":{"id":"H2IvUhbHKRnp"}},{"cell_type":"code","source":["df_train = '/content/drive/MyDrive/Masters_Thesis/Dataset/topicReviewText/topicReviewText_newtrain2.csv'\n","df_test = '/content/drive/MyDrive/Masters_Thesis/Dataset/topicReviewText/topicReviewText_newtest2.csv'\n","target_list = 'encoded_sub_topic'"],"metadata":{"id":"LXAIBfmRmCqI","executionInfo":{"status":"ok","timestamp":1681957896304,"user_tz":300,"elapsed":4,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","train_loader, valid_loader = get_data_loaders(df_train, df_test, tokenizer, train_batch_size = 8, valid_batch_size = 8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"No8Qt1lMnRt6","executionInfo":{"status":"ok","timestamp":1681957981220,"user_tz":300,"elapsed":2982,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}},"outputId":"3a736a2e-1db1-4079-985f-20feb887c96f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True)\n"]}]},{"cell_type":"markdown","source":["### Model"],"metadata":{"id":"UIr_PPcJKOc9"}},{"cell_type":"code","source":["model = BERTModel()\n","model.to(device)\n","loss_function = torch.nn.CrossEntropyLoss()\n","LEARNING_RATE = 2e-5\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["2e2b40c5004045d487f581ada1307c0a","ced28e7ea16e4c508bf6870bae93ef96","fb84e9c3af4340b39edc58fb0c031f7e","f4b5579f52894abfbf498cdd3cc21f56","37462b8a7dcb4e13b9f51903405f014e","37be122c4c874906ab3ceed8ec68abcb","a06cd0ee43a74686872c1d4ef3a5ebd2","f705ec386bdd4bbc9453ee160fc4bf51","01c8a1b8326043d5afa98d18d61838d7","749a45199b4d47f5b6f93fcfb31d84c8","d666ca3e217440a89694739e7da7c8ff"]},"id":"CN5NT4OVmayE","executionInfo":{"status":"ok","timestamp":1681957993702,"user_tz":300,"elapsed":9237,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}},"outputId":"fc091320-6340-450f-ba5a-9cae94624318"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2b40c5004045d487f581ada1307c0a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["train(total_epoch=20, model=model, train_loader=train_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okq5OPLzoujK","outputId":"020dcc84-ed27-4822-ee14-874a1909d83b","executionInfo":{"status":"ok","timestamp":1681963793366,"user_tz":300,"elapsed":5799667,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":[" Epoch  |  Train Loss  | Train Accuracy |  Elapsed \n","---------------------------------------------------\n","   1    |   0.316357   |  88.321925   |   4.86   \n","   2    |   0.184578   |  93.600913   |   4.82   \n","   3    |   0.146461   |  94.969923   |   4.82   \n","   4    |   0.111218   |  96.204107   |   4.83   \n","   5    |   0.089359   |  97.261979   |   4.83   \n","   6    |   0.074536   |  97.718316   |   4.83   \n","   7    |   0.065599   |  97.925742   |   4.83   \n","   8    |   0.048748   |  98.454677   |   4.83   \n","   9    |   0.048157   |  98.558390   |   4.83   \n","  10    |   0.040121   |  98.703588   |   4.83   \n","  11    |   0.038609   |  98.859158   |   4.83   \n","  12    |   0.035741   |  98.900643   |   4.83   \n","  13    |   0.037919   |  98.838415   |   4.83   \n","  14    |   0.040065   |  98.796930   |   4.83   \n","  15    |   0.024363   |  99.242896   |   4.84   \n","  16    |   0.023934   |  99.398465   |   4.84   \n","  17    |   0.030140   |  99.139183   |   4.84   \n","  18    |   0.027433   |  99.128811   |   4.83   \n","  19    |   0.026221   |  99.139183   |   4.84   \n","  20    |   0.023868   |  99.180668   |   4.83   \n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"14ecQgbCkAib"}},{"cell_type":"code","source":["predictions = valid(model, valid_loader) "],"metadata":{"id":"I5_RNce5tAie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681964277261,"user_tz":300,"elapsed":23864,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}},"outputId":"ebb7f553-06f5-4458-f8a8-97e20a2d6f86"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":[" Valid Loss  | Valid Accuracy |  Elapsed \n","-----------------------------------------\n","  0.429929   |   91.649777    |   0.39   \n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Masters_Thesis/Models/BERT/SubTopicPredictedTopics/SubTopicPredictedTopics_only_back_01\"\n","saveModel(model=model, path=path)"],"metadata":{"id":"7f8cYzuQXG6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681964173220,"user_tz":300,"elapsed":1800,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}},"outputId":"9e724441-1fa2-4dde-ef5b-137ff96eb693"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["All files saved\n"]}]},{"cell_type":"code","source":["saveCSVValidationResult(predictions,path)"],"metadata":{"id":"eM_ZTVKUXInj","executionInfo":{"status":"ok","timestamp":1681964174962,"user_tz":300,"elapsed":811,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### Data Preprocessing & DataLoader"],"metadata":{"id":"x6yCYZsTKK1O"}},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","        self.df = df\n","        self.max_len = max_len\n","        self.text = df.reviewText\n","        self.tokenizer = tokenizer\n","        self.targets = df[target_list].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True\n","        )\n","        #the attention_masks and token type ids, everything is returned in a dictionary format\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.long),\n","            'text' : text\n","        }\n","\n","def get_data_loaders(train_dataframe, valid_dataframe, tokenizer, max_len=512, train_batch_size=16, valid_batch_size=16, learning_rate=2e-5):\n","\n","    Train_Dataframe = pd.read_csv(train_dataframe)\n","    Validation_Dataframe = pd.read_csv(valid_dataframe)\n","    print(tokenizer)\n","    train_dataset = CustomDataset(Train_Dataframe, tokenizer, max_len)\n","    valid_dataset = CustomDataset(Validation_Dataframe, tokenizer, max_len)\n","    train_loader = DataLoader(train_dataset, batch_size=train_batch_size,\n","                              num_workers=1, shuffle=True, pin_memory=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=valid_batch_size,\n","                              num_workers=1, shuffle=False, pin_memory=True)\n","\n","    return train_loader, valid_loader"],"metadata":{"id":"QK0Aj_4ORs4r","executionInfo":{"status":"ok","timestamp":1681957891108,"user_tz":300,"elapsed":595,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### BERT Model"],"metadata":{"id":"nhkHzJ9vKHFp"}},{"cell_type":"code","source":["class BERTModel(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTModel, self).__init__()\n","        self.roberta = AutoModel.from_pretrained('roberta-base')\n","        self.dropout = torch.nn.Dropout(0.5)\n","        self.fc = torch.nn.Linear(768, 5)\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        _, features = self.roberta(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n","        features = self.dropout(features)\n","        output = self.fc(features)\n","        return output"],"metadata":{"id":"rPo0VQ-MmMJZ","executionInfo":{"status":"ok","timestamp":1681957888745,"user_tz":300,"elapsed":2,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Training & Validation"],"metadata":{"id":"NnDT6iECKCz3"}},{"cell_type":"code","execution_count":27,"metadata":{"id":"EkEjh-3UQIfL","executionInfo":{"status":"ok","timestamp":1681964249646,"user_tz":300,"elapsed":468,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"outputs":[],"source":["\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct\n","\n","def train(total_epoch, model, train_loader):\n","    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train Accuracy':^12} | {'Elapsed':^9}\")\n","    print(\"-\"*51)\n","    for epoch in range(total_epoch): \n","      t0_epoch = time.time() \n","      tr_loss = 0\n","      n_correct = 0\n","      nb_tr_steps = 0\n","      nb_tr_examples = 0\n","      model.train()\n","      for _,data in enumerate(train_loader, 0):\n","          ids = data['ids'].to(device, dtype = torch.long)\n","          mask = data['mask'].to(device, dtype = torch.long)\n","          token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","          targets = data['targets'].to(device, dtype = torch.long)\n","\n","          outputs = model(ids, mask, token_type_ids)\n","        \n","          loss = loss_function(outputs, targets)\n","          tr_loss += loss.item()\n","          big_val, big_idx = torch.max(outputs.data, dim=1)\n","          n_correct += calcuate_accu(big_idx, targets)\n","\n","          nb_tr_steps += 1\n","          nb_tr_examples+=targets.size(0)\n","          \n","          optimizer.zero_grad()\n","          loss.backward()\n","          # # When using GPU\n","          optimizer.step()\n","\n","      time_elapsed = (time.time() - t0_epoch)/60\n","      epoch_loss = tr_loss/nb_tr_steps\n","      epoch_accu = (n_correct*100)/nb_tr_examples\n","      print(f\"{epoch + 1:^7} | {epoch_loss:^12.6f} | {epoch_accu:^12.6f} | {time_elapsed:^9.2f}\")\n"," \n","\n","def valid(model, testing_loader):\n","    print(f\"{'Valid Loss':^12} | {'Valid Accuracy':^12} | {'Elapsed':^9}\")\n","    print(\"-\"*41)\n","    model.eval()\n","    t0_epoch = time.time() \n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    predictions = []\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","          ids = data['ids'].to(device, dtype = torch.long)\n","          mask = data['mask'].to(device, dtype = torch.long)\n","          token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","          targets = data['targets'].to(device, dtype = torch.long)\n","          text = data['text']\n","          outputs = model(ids, mask, token_type_ids)\n","\n","\n","          loss = loss_function(outputs, targets)\n","          tr_loss += loss.item()\n","          big_val, big_idx = torch.max(outputs.data, dim=1)\n","          n_correct += calcuate_accu(big_idx, targets)\n","\n","          nb_tr_steps += 1\n","          nb_tr_examples+=targets.size(0)\n","\n","          for i in range(len(text)):\n","            predictions.append({\n","                'text': text[i],\n","                'predicted': switch_issue(big_idx[i].item()),\n","                'target': switch_issue(targets[i].item())\n","                })\n","\n","    time_elapsed = (time.time() - t0_epoch)/60                \n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"{epoch_loss:^12.6f} | {epoch_accu:^14.6f} | {time_elapsed:^9.2f}\")\n","    return predictions\n","\n","def switch_issue(issue_type):\n","    switcher = {\n","      4: 'Product Description Issue',\n","      3: 'Delivery and Return Issue',\n","      2: 'Design Issue',\n","      1: 'Quality Issue',\n","      0: 'Product Authenticity Issue'\n","      }\n","    return switcher.get(issue_type, \"Invalid Issue Type\")"]},{"cell_type":"markdown","source":["### Save Files"],"metadata":{"id":"co42W2Wk7Lsj"}},{"cell_type":"code","source":["def saveModel(model, path):\n","  MODEL_PATH = path+'/model.pth'\n","  torch.save(model.state_dict(), MODEL_PATH)  \n","  print('All files saved')\n","\n","def loadModel(path):\n","  MODEL_PATH = path+'/model2.pth'\n","  model.load_state_dict(torch.load(MODEL_PATH))\n","\n","  return model, tokenizer"],"metadata":{"id":"5w-rUwH1crVv","executionInfo":{"status":"ok","timestamp":1681964167185,"user_tz":300,"elapsed":3,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def saveCSVValidationResult(predictions, path):\n","    path = path+\"/result.csv\"\n","    with open(path, mode='w', newline='', encoding='utf-8') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['Text', 'Predicted', 'Target'])\n","        for example in predictions:\n","            writer.writerow([example['text'], example['predicted'], example['target']])"],"metadata":{"id":"HOrTHj2TemRg","executionInfo":{"status":"ok","timestamp":1681964169086,"user_tz":300,"elapsed":325,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0Jnnv_t34HXw","executionInfo":{"status":"ok","timestamp":1681957886190,"user_tz":300,"elapsed":3,"user":{"displayName":"Setimental Anaysis","userId":"08661727469203288539"}}},"execution_count":7,"outputs":[]}]}